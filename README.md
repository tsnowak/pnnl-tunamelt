
# Introduction

This code accompanies the paper `TBD` which studies possible methods for filtering turbine motion out of underwater acoustic camera videos in order to assist with fish detection and underwater turbine monitoring.

We operate on `.mp4` files transcoded from `.ddfs` generated by a DIDSON acoustic camera due to their greater ease of use and the plentiful tools available for doing so.

While our work focuses on improving filtering around underewater turbines, we measure the performance of our filters by determining which frames do not contain targets of interest (and can thus be disguarded by regulators). Therefore we need some method to detect fish. We show that even using a simple contour detector (aka just things over a certain area in the image) that we can readily detect fish in our well-filtered videos.

# Prerequisites

While all package dependencies are handled by `conda` and `PyPi` these managers will need to be installed before hand.

- [Miniconda](https://docs.conda.io/en/latest/miniconda.html): Miniconda setup script downloads. Will also contain pip/PyPi.

# Setup

Once `conda` is setup on your machine, you can go ahead and setup the development environment.

```
# creates a conda environment for this code
conda env create -n fish

# activates the new environment
conda activate fish

# installs the software for this project into the environment
```

# Intuition

The fish contained in these `.mp4`s are particularly difficult to see (detect). Looking at the original video, I'm not sure I personally catch all of them. Efforts are furthermore hindered by a significant amount of particulate matter in the water column. Nonetheless, these takeaways from watching the video guided the design of my video processing pipeline:

- processing does not need to occur live/in-situ
- consistently static objects can be removed

- SOMETHING BIOLOGICAL
- tortuousity (fish / non-linear movements)
- brightness
- false positives fine

- fourier transform pixels should be good

-

# Data Types

## Dataset and DataLoader Example

``` python
# creates an iterator which outputs dataset.aligned_data one at a time when the next(dataloader) function is called
# aligned_data contains a tuples of (video, label) pairs
dataloader = DataLoader(Dataset=
                videos = 'path/to/mp4s',
                labels = 'path/to/labels'
            )

# contains aligned video, label pairs
vid, label = next(dataloader)
```

## Annotations Structure

``` python
{'test': [
    {
        'filename': '2010-09-08_074500_HF_S002_S001.mp4',
        'tracks': [
            {
                'frames': [
                    {'box': ((486, 1011), (542, 1062)),
                    'frame': 16,
                    'keyframe': 1,
                    'occluded': 0,
                    'outside': 0},
                    {'box': ((455, 1016), (511, 1067)), ...
                ]
                'label': 'target',
                'track_id': 0
            },
                'frames': ...
        ],
        'video_id': 12,
        'video_length': 160,
        'video_shape': {'height': 1792, 'width': 1032}
    }
]
} 
```
