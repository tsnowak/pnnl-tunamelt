
# Introduction

This code accompanies the paper `TBD` which studies possible methods for filtering turbine motion out of underwater acoustic camera videos in order to assist with fish detection and underwater turbine monitoring.

We operate on `.mp4` files transcoded from `.ddfs` generated by a DIDSON acoustic camera due to their greater ease of use and the plentiful tools available for doing so.

While our work focuses on improving filtering around underewater turbines, the motivation for this work is to enhance regulators' ability to assess fish interaction with water power devices. We therefore evaluate the efficacy of our filters by implementing them in a greater system used to determine when a potential fish target is in view. We then measure the accuracy of our determinations against expert-labeled, group-truth data denoting when a target is in view. This fish-in-frame detection system uses an out-of-the-box contour detection method from OpenCV.

# Prerequisites

While all package dependencies are handled by `conda` and `PyPi` these managers will need to be installed before hand.

- [Miniconda](https://docs.conda.io/en/latest/miniconda.html): Miniconda setup script downloads. Will also contain pip/PyPi.

# Setup

Once `conda` is setup on your machine, you can go ahead and setup the development environment.

``` bash
# creates a conda environment for this code
conda create -n turbx python=3.9

# activates the new environment
conda activate turbx

# installs the software for this project into the environment
conda env update --file env.yml
```

# Data Types

## Dataset and DataLoader Example

``` python
# creates an iterator which outputs dataset.aligned_data one at a time when the next(dataloader) function is called
# aligned_data contains a tuples of (video, label) pairs
dataloader = DataLoader(Dataset=
                videos = 'path/to/mp4s',
                labels = 'path/to/labels'
            )

# contains aligned video, label pairs
vid, label = next(dataloader)
```

## Exporting Vdieo Annotations from CVAT

Exporting all project annotations does not preserve per-video frame information. We therefore have to export each task manually. To do so using the CVAT CLI create a python environment [via the linked](https://openvinotoolkit.github.io/cvat/docs/manual/advanced/cli/#usage) then use the below to export annotations from a specific task:

``` bash
# format = CVAT for images 1.1
# task = 103
cli.py dump --format "CVAT for images 1.1" 103 output.zip
```

## Final Video Annotations Structure

See `annotations.xml` for raw annotation structure.

``` python
{'test': [
    {
        'filename': '2010-09-08_074500_HF_S002_S001.mp4',
        'tracks': [
            {
                'frames': [
                    {'box': ((486, 1011), (542, 1062)),
                    'frame': 16,
                    'keyframe': 1,
                    'occluded': 0,
                    'outside': 0},
                    {'box': ((455, 1016), (511, 1067)), ...
                ]
                'label': 'target',
                'track_id': 0
            },
                'frames': ...
        ],
        'video_id': 12,
        'video_length': 160,
        'video_shape': {'height': 1792, 'width': 1032}
    }
]
} 
```

# Running Tests

``` bash
# All tests
pytest -s

# Data-related tests
pytest -s test/data

# Dataloader-specific tests
pytest -s test/data/test_dataloader.py

# A specific suite of dataloader tests
pytest -s test/data/test_dataloader.py -k test_label

# With durations
pytest --durations=0 /test/data

# With profiling
python -m cProfile -m pytest --durations=0 /test/data
```
