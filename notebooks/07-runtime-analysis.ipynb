{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runtime analysis desired takeaway:\n",
    "- illustrate added processing time from detection association (really big when lots of predictions/weak filtering)\n",
    "\n",
    "Runtime analysis approach:\n",
    "- Was runtime information collected during results generation?\n",
    "    - No; folders and json were all created at same time (in results folder)\n",
    "- Estimate runtime without running on everything (1 passthrough test set?)\n",
    "    - For 20/75/88: runtime - w/ assoc vs. w/o assoc\n",
    "    - For 20/75/88: N detections - w/assoc vs. w/o assoc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, OrderedDict, Union\n",
    "\n",
    "from afdme import REPO_PATH\n",
    "from afdme.filter import common, dft\n",
    "from afdme.run import run\n",
    "from afdme.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def multirun_exp(param_batches, args):\n",
    "\n",
    "    # create the dataset - do this once, do dataloader.reset() each batch\n",
    "    data_path = \"\"\n",
    "    label_path = \"\"\n",
    "    if args[\"dataset\"] == \"test\":\n",
    "        data_path = f\"{args['path']}/mp4/batched_test\"\n",
    "        label_path = f\"{args['path']}/labels/cvat-video-1.1/batched_test\"\n",
    "    else:\n",
    "        data_path = f\"{args['path']}/mp4/{args['dataset']}\"\n",
    "        label_path = f\"{args['path']}/labels/cvat-video-1.1/{args['dataset']}\"\n",
    "    dataloader = DataLoader(\n",
    "        Dataset(videos=data_path, labels=label_path), split=args[\"dataset\"]\n",
    "    )\n",
    "\n",
    "    for itr, params in enumerate(param_batches):\n",
    "\n",
    "        fps = 10\n",
    "        frame_delay = 1.0 / fps\n",
    "\n",
    "        # reinitialize filters given params\n",
    "        mean_filter = common.MeanFilter(fps=fps, params=params[\"mean_filter\"])\n",
    "        turbine_filter = dft.DFTFilter(fps=fps, params=params[\"turbine_filter\"])\n",
    "        denoise_filter = common.GaussianBlurDenoiseFilter(\n",
    "            fps=fps, params=params[\"denoise_filter\"]\n",
    "        )\n",
    "        intensity_filter = common.IntensityFilter(\n",
    "            fps=fps, params=params[\"intensity_filter\"]\n",
    "        )\n",
    "        contour_filter = common.ContourFilter(params=params[\"contour_filter\"])\n",
    "        tracklet_association = common.TrackletAssociation(\n",
    "            params=params[\"tracklet_association\"]\n",
    "        )\n",
    "\n",
    "        # automatically load filters at runtime and ensure required filters are present\n",
    "        # ie {\"original\": None} and {\"contour_filter\": contour_filter}\n",
    "        filters = OrderedDict()\n",
    "        filters.update({\"original\": None})\n",
    "        # NOTE: I think, but am not sure all these filters are order-agnostic\n",
    "        for filter in args[\"filters\"]:\n",
    "            try:\n",
    "                filters.update({filter: eval(filter)})\n",
    "            except SyntaxError:\n",
    "                raise SyntaxError(\n",
    "                    \"The only valid filters to pass to --filters are: \"\n",
    "                    + \"[mean_filter, turbine_filter, \"\n",
    "                    + \"denoise_filter, intensity_filter, \"\n",
    "                    + \"tracklet_association\"\n",
    "                )\n",
    "        # always end with contour_filter\n",
    "        filters.update({\"contour_filter\": contour_filter})\n",
    "        # unless tracklet_association present\n",
    "        if \"tracklet_association\" in filters.keys():\n",
    "            filters.move_to_end(\"tracklet_association\")\n",
    "\n",
    "        # hardcoded equivalent\n",
    "        # filters = OrderedDict(\n",
    "        #    [\n",
    "        #        (\"original\", None),\n",
    "        #        (\"mean_filter\", mean_filter),\n",
    "        #        (\"turbine_filter\", turbine_filter),\n",
    "        #        (\"denoise_filter\", denoise_filter),\n",
    "        #        (\"intensity_filter\", intensity_filter),\n",
    "        #        (\"contour_filter\", contour_filter),\n",
    "        #        #            (\"tracklet_association\", tracklet_association),\n",
    "        #    ]\n",
    "        # )\n",
    "\n",
    "        # set self_idx to 0 to restart runs through dataset\n",
    "        dataloader.reset()\n",
    "\n",
    "        # run the filters on every video in the dataset; or on N=<max_vid_itrs> videos (for testing)\n",
    "        run(\n",
    "            itr,\n",
    "            filters,\n",
    "            params,\n",
    "            dataloader,\n",
    "            run_path,\n",
    "            max_vid_itrs=10000000,\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "afdme",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
