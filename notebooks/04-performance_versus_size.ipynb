{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance VS Size Analysis\n",
    "\n",
    "Calculate TPFN per target then plot/averge by size?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import logging\n",
    "from math import ceil, floor\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Union, Dict, Optional\n",
    "from multiprocessing import Process, Pool\n",
    "import psutil\n",
    "import base64\n",
    "import asyncio\n",
    "import cv2\n",
    "import imageio as iio\n",
    "import numpy as np\n",
    "from IPython.core.display import HTML\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.fft import fft, fftfreq, fftn, fftshift\n",
    "from pprint import pprint\n",
    "from scipy.stats import anderson_ksamp, ks_2samp\n",
    "\n",
    "from tunamelt import REPO_PATH, log\n",
    "from tunamelt.vis import (\n",
    "    calc_tfpnr,\n",
    "    calc_tdr,\n",
    "    calc_frames_removed,\n",
    "    label_to_per_frame_list,\n",
    ")\n",
    "from tunamelt.metrics import (\n",
    "    calc_box_area,\n",
    "    avg_box_area,\n",
    "    boxes_to_binary,\n",
    "    target_detection_rate,\n",
    "    tfpnr,\n",
    "    safe_division,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys for splitting and organizing loaded data\n",
    "\n",
    "\n",
    "def resolve_data_split(k):\n",
    "    name = k.name\n",
    "    # train\n",
    "    if name == \"20\" or name == \"75\" or name == \"88\":\n",
    "        return \"train\"\n",
    "    # test\n",
    "    if name == \"0\" or name == \"1\" or name == \"2\":\n",
    "        return \"test\"\n",
    "\n",
    "\n",
    "def resolve_param_set(k):\n",
    "    name = k.name\n",
    "    if name == \"20\" or name == \"0\":\n",
    "        return \"20\"\n",
    "    if name == \"75\" or name == \"2\":\n",
    "        return \"75\"\n",
    "    if name == \"88\" or name == \"1\":\n",
    "        return \"88\"\n",
    "\n",
    "\n",
    "def resolve_color_split(split):\n",
    "    if split == \"train\":\n",
    "        return \"b\"\n",
    "    if split == \"test\":\n",
    "        return \"o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and organize results\n",
    "\n",
    "\n",
    "def load_results(base_path, results_dict):\n",
    "    split = resolve_data_split(base_path)\n",
    "    param_set_name = resolve_param_set(base_path)\n",
    "\n",
    "    # add to dictionary for reference later\n",
    "    if not split in results_dict.keys():\n",
    "        results_dict[split] = {param_set_name: {}}\n",
    "    else:\n",
    "        results_dict[split].update({param_set_name: {}})\n",
    "\n",
    "    args_json = Path(base_path / \"args.json\")\n",
    "    if args_json.exists():\n",
    "        with open(str(args_json), \"r\") as f:\n",
    "            log.info(json.load(f))\n",
    "\n",
    "    # log.info(\"Per frame:\")\n",
    "    # log.info(\"id:, FPR, FNR, Target Detection Rate, % Frames Removed, % Neg Frames Removed\")\n",
    "    pos_frames, neg_frames = [], []\n",
    "    pos_preds, neg_preds = [], []\n",
    "\n",
    "    # accumulate run directories\n",
    "    subdirs = next(os.walk(str(base_path)))[1]\n",
    "    param_set_path = base_path\n",
    "    param_set_results = []\n",
    "    param_set = param_set_path.name\n",
    "    # load every json for that run and append to param_set_results\n",
    "    for f_name in param_set_path.glob(\"**/*.json\"):\n",
    "        with open(f_name, \"r\") as f:\n",
    "            params = json.load(f)\n",
    "            param_set_results.append((params, param_set))\n",
    "\n",
    "    # for each video\n",
    "    for result, param_set_id in param_set_results[2:]:\n",
    "        # per frame binary label and pred\n",
    "        binary_label, binary_pred, _ = calc_tfpnr(\n",
    "            result[\"label\"], result[\"prediction\"], show=False, save=False\n",
    "        )\n",
    "\n",
    "        # per frame list of avg box area\n",
    "        avg_box_area_per_frame = [\n",
    "            avg_box_area(box) for box in label_to_per_frame_list(result[\"label\"])\n",
    "        ]\n",
    "\n",
    "        # create list of all binary labels and preds for positive and negative frames combined with bounding boxe areas\n",
    "        y = zip(binary_label, binary_pred, avg_box_area_per_frame)\n",
    "        for x in y:\n",
    "            if x[0] == 1:\n",
    "                pos_frames.append(x)\n",
    "                pos_preds.append((int(x[0] == x[1]), x[2]))\n",
    "            else:\n",
    "                neg_frames.append(x)\n",
    "                neg_preds.append(int(x[0] == x[1]))\n",
    "\n",
    "    results_dict[split][param_set_name][\"pos_preds\"] = pos_preds\n",
    "    results_dict[split][param_set_name][\"pos_frames\"] = pos_frames\n",
    "    results_dict[split][param_set_name][\"neg_preds\"] = neg_preds\n",
    "    results_dict[split][param_set_name][\"neg_frames\"] = neg_frames\n",
    "\n",
    "    # should update results_dict\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the results from the base paths\n",
    "\n",
    "base_paths = [\n",
    "    Path(f\"{REPO_PATH}/notebooks/outputs/with-tracklets/train/20\"),\n",
    "    Path(f\"{REPO_PATH}/notebooks/outputs/with-tracklets/train/75\"),\n",
    "    Path(f\"{REPO_PATH}/notebooks/outputs/with-tracklets/train/88\"),\n",
    "    Path(f\"{REPO_PATH}/notebooks/outputs/ablation/2022-12-16/12-25-41/0\"),\n",
    "    Path(f\"{REPO_PATH}/notebooks/outputs/ablation/2022-12-16/12-25-41/1\"),\n",
    "    Path(f\"{REPO_PATH}/notebooks/outputs/ablation/2022-12-16/12-25-41/2\"),\n",
    "]\n",
    "\n",
    "results_dict = {}\n",
    "for base_path in base_paths:\n",
    "    load_results(base_path, results_dict)\n",
    "\n",
    "# verify it's full\n",
    "log.info(results_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot bins of true/false preds\n",
    "\n",
    "\n",
    "def plot_tpfn_bins(pos_preds):\n",
    "    fig, ax = plt.subplots()\n",
    "    true_pos_preds = [x[1] for x in pos_preds if x[0] == 1]\n",
    "    false_pos_preds = [x[1] for x in pos_preds if x[0] == 0]\n",
    "    ax.hist(true_pos_preds, bins=50)\n",
    "    ax.hist(false_pos_preds, bins=50)\n",
    "\n",
    "\n",
    "# plot_tpfn_bins(pos_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot binned positive predictions with error\n",
    "\n",
    "\n",
    "def plot_binned_pos_preds(pos_preds):\n",
    "    # bin preds by size\n",
    "    bin_size = 500\n",
    "    binned_list = [[] for x in range(ceil(max([y[1] for y in pos_preds]) / bin_size))]\n",
    "    for x in pos_preds:\n",
    "        bin = floor(x[1] / bin_size)\n",
    "        binned_list[bin].append(x)\n",
    "\n",
    "    bin_stats = []\n",
    "    for idx, bin in enumerate(binned_list):\n",
    "        bin_preds = [x[0] for x in bin]\n",
    "        bin_sizes = [x[1] for x in bin]\n",
    "        bin_mean = np.mean(bin_preds)\n",
    "        bin_std = np.std(bin_preds)\n",
    "        bin_stats.append((bin_mean, bin_std, (idx * bin_size, (idx + 1) * bin_size)))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    # x_start, height, width (list of 100s)\n",
    "    plt.title(f\"{base_path}\")\n",
    "    plt.bar(\n",
    "        [x[2][0] for x in bin_stats],\n",
    "        height=[x[0] for x in bin_stats],\n",
    "        width=[bin_size for _ in bin_stats],\n",
    "        yerr=[x[1] for x in bin_stats],\n",
    "        ecolor=\"black\",\n",
    "        capsize=5,\n",
    "    )\n",
    "    # true_pos_preds = [x[1] for x in pos_preds if x[0] == 1]\n",
    "    # false_pos_preds = [x[1] for x in pos_preds if x[0] == 0]\n",
    "    # ax.scatter([x[1] for x in pos_preds], [x[0] for x in pos_preds], )\n",
    "    # ax.hist(true_pos_preds, bins=50)\n",
    "    # ax.hist(false_pos_preds, bins=50)\n",
    "    # ax.set_xscale(\"log\")\n",
    "\n",
    "\n",
    "# plot_binned_pos_preds(pos_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_dist(dist, sampling):\n",
    "    dist_x, dist_y = dist\n",
    "    # if no values in set then its resampled CDF is all 0s? (or is it all 1s?)\n",
    "    if (len(dist_x) == 0) or (len(dist_y) == 0):\n",
    "        return np.zeros(len(sampling))\n",
    "    else:\n",
    "        return np.interp(x=sampling, xp=dist_x, fp=dist_y)\n",
    "\n",
    "\n",
    "def compose_cdfs(results):\n",
    "    pos_frames = results[\"pos_frames\"]\n",
    "\n",
    "    # organize targets data grams\n",
    "\n",
    "    # sort all target detections by size\n",
    "    sorted_pos_frames = sorted(pos_frames, key=lambda y: y[2])\n",
    "    # put predictions into an array\n",
    "    pos_frames_preds = np.array([x[1] for x in sorted_pos_frames])\n",
    "    # put sample sizes into an array\n",
    "    pos_frames_sizes = np.array([x[2] for x in sorted_pos_frames])\n",
    "\n",
    "    # id false negative indices\n",
    "    fn_idxs = np.where(pos_frames_preds == 0)[0]\n",
    "    # id true positive indices\n",
    "    tp_idxs = np.where(pos_frames_preds == 1)[0]\n",
    "\n",
    "    # compose lists of tp/fn targets by size\n",
    "    fn_frames = np.array([pos_frames_sizes[i] for i in fn_idxs])\n",
    "    tp_frames = np.array([pos_frames_sizes[i] for i in tp_idxs])\n",
    "\n",
    "    # calculate cdfs\n",
    "\n",
    "    c_cdfx = pos_frames_sizes\n",
    "    c_cdfy = 1.0 * np.arange(len(pos_frames_sizes)) / (len(pos_frames_sizes) - 1)\n",
    "\n",
    "    tp_cdfx = tp_frames\n",
    "    tp_cdfy = 1.0 * np.arange(len(tp_frames)) / (len(tp_frames) - 1)\n",
    "\n",
    "    fn_cdfx = fn_frames\n",
    "    fn_cdfy = 1.0 * np.arange(len(fn_frames)) / (len(fn_frames) - 1)\n",
    "\n",
    "    # resample cdfs along same values\n",
    "    n_samples = 1000\n",
    "    min_val = np.min(np.hstack((c_cdfx, tp_cdfx, fn_cdfx)))\n",
    "    max_val = np.max(np.hstack((c_cdfx, tp_cdfx, fn_cdfx)))\n",
    "    lin_sampling = np.linspace(start=min_val, stop=max_val, num=n_samples)\n",
    "\n",
    "    c_cdfys = resample_dist((c_cdfx, c_cdfy), lin_sampling)\n",
    "    tp_cdfys = resample_dist((tp_cdfx, tp_cdfy), lin_sampling)\n",
    "    fn_cdfys = resample_dist((fn_cdfx, fn_cdfy), lin_sampling)\n",
    "    # c_cdfxs, c_cdfys = resample_dist((c_cdfx, c_cdfy), lin_sampling)\n",
    "    # log.info(c_cdfxs)\n",
    "\n",
    "    results.update(\n",
    "        {\n",
    "            \"c_cdf\": {\n",
    "                \"original\": (c_cdfx, c_cdfy),\n",
    "                \"resampled\": (lin_sampling, c_cdfys),\n",
    "            },\n",
    "            \"tp_cdf\": {\n",
    "                \"original\": (tp_cdfx, tp_cdfy),\n",
    "                \"resampled\": (lin_sampling, tp_cdfys),\n",
    "            },\n",
    "            \"fn_cdf\": {\n",
    "                \"original\": (fn_cdfx, fn_cdfy),\n",
    "                \"resampled\": (lin_sampling, fn_cdfys),\n",
    "            },\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in results_dict.items():\n",
    "    for ki, vi in v.items():\n",
    "        compose_cdfs(vi)\n",
    "\n",
    "# are these getting filled? - yes\n",
    "# log.info(results_dict['train']['20']['tp_cdf']['original'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting functions\n",
    "\n",
    "\n",
    "def plot_cdf(results_dict, split, params, treatment, sampling):\n",
    "    c_cdf = results_dict[split][params][\"c_cdf\"][sampling]\n",
    "    tp_cdf = results_dict[split][params][\"tp_cdf\"][sampling]\n",
    "    fn_cdf = results_dict[split][params][\"fn_cdf\"][sampling]\n",
    "\n",
    "    if \"tp\" in treatment:\n",
    "        label = \"TP\"\n",
    "        t_cdf = tp_cdf\n",
    "    elif \"fn\" in treatment:\n",
    "        label = \"FN\"\n",
    "        t_cdf = fn_cdf\n",
    "    else:\n",
    "        raise ValueError(\"Distribution is not tp or fn\")\n",
    "\n",
    "    plt.plot(*c_cdf, linestyle=\"dashed\", color=\"k\")\n",
    "    plt.plot(*t_cdf, linestyle=\"solid\", color=\"k\")\n",
    "    # plt.vlines([perc], ymin=0, ymax=ymax_val, linestyles='dotted', colors=resolve_color_split(base_path))\n",
    "    plt.xscale(\"log\")\n",
    "\n",
    "\n",
    "def plot_cdf_err(results_dict, split, params, treatment, sampling):\n",
    "    c_cdf = results_dict[split][params][\"c_cdf\"][sampling]\n",
    "    tp_cdf = results_dict[split][params][\"tp_cdf\"][sampling]\n",
    "    fn_cdf = results_dict[split][params][\"fn_cdf\"][sampling]\n",
    "\n",
    "    if \"tp\" in treatment:\n",
    "        label = \"TP\"\n",
    "        t_cdf = tp_cdf\n",
    "    elif \"fn\" in treatment:\n",
    "        label = \"FN\"\n",
    "        t_cdf = fn_cdf\n",
    "    else:\n",
    "        raise ValueError(\"Distribution is not tp or fn\")\n",
    "\n",
    "    ad, ks = test_statistics(results_dict, split, params, treatment, sampling)\n",
    "    if len(c_cdf[1]) != len(t_cdf[1]):\n",
    "        log.info(\"Not Plotting! Are the samplings of the two distributions the same?\")\n",
    "        plt.legend(\n",
    "            [\n",
    "                f\"{split.capitalize()} Split Positive Targets\",\n",
    "                f\"{label} Predictions using Param Set {params}\",\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        err = []\n",
    "        for i, _ in enumerate(c_cdf[0]):\n",
    "            err.append(np.abs(c_cdf[1][i] - t_cdf[1][i]))\n",
    "\n",
    "        plt.plot(c_cdf[0], err, linestyle=\"dashed\", color=\"r\")\n",
    "        plt.plot([], [], \" \")\n",
    "        plt.plot([], [], \" \")\n",
    "        plt.legend(\n",
    "            [\n",
    "                f\"{split.capitalize()} Split Positive Targets\",\n",
    "                f\"{label} Predictions using Param Set {params}\",\n",
    "                \"Error\",\n",
    "                f\"AD Significance: {round(ad, 4)}\",\n",
    "                f\"KS P-Value: {round(ks, 4)}\",\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    plt.ylabel(\"Cumulative Probability\")\n",
    "    plt.xlabel(\"Target Size\")\n",
    "    plt.show()\n",
    "    return None\n",
    "\n",
    "\n",
    "def test_statistics(results_dict, split, params, treatment, sampling):\n",
    "    control = results_dict[split][params][\"pos_frames\"]\n",
    "    treatment_arr = results_dict[split][params][treatment][\"original\"][0]\n",
    "\n",
    "    ad = anderson_ksamp([[y[2] for y in control], treatment_arr])\n",
    "    ks = ks_2samp([y[2] for y in control], treatment_arr)\n",
    "    log.info(f\"Anderson-Darling pvalue for {treatment}: {ad.significance_level}\")\n",
    "    log.info(f\"Kolmogorov-Smirnov pvalue {treatment}: {ks.pvalue}\")\n",
    "    return ad.significance_level, ks.pvalue\n",
    "\n",
    "\n",
    "split = \"train\"\n",
    "sampling = \"resampled\"\n",
    "\n",
    "# plot_cdf((c_cdfx, c_cdfy), (tp_cdfx, tp_cdfy))\n",
    "# plot_cdf((c_cdfx, c_cdfy), (fn_cdfx, fn_cdfy))\n",
    "params = \"20\"\n",
    "treatment = \"tp_cdf\"\n",
    "plot_cdf(results_dict, split, params, treatment, sampling)\n",
    "plot_cdf_err(results_dict, split, params, treatment, sampling)\n",
    "# test_statistics(results_dict, split, params, treatment, sampling)\n",
    "\n",
    "params = \"75\"\n",
    "treatment = \"tp_cdf\"\n",
    "plot_cdf(results_dict, split, params, treatment, sampling)\n",
    "plot_cdf_err(results_dict, split, params, treatment, sampling)\n",
    "# test_statistics(results_dict, split, params, treatment, sampling)\n",
    "\n",
    "params = \"88\"\n",
    "treatment = \"tp_cdf\"\n",
    "plot_cdf(results_dict, split, params, treatment, sampling)\n",
    "plot_cdf_err(results_dict, split, params, treatment, sampling)\n",
    "# test_statistics(results_dict, split, params, treatment, sampling)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multirun\n",
    "\n",
    "Plot train and test runs together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_paths = [\n",
    "    # Path(f\"{REPO_PATH}/notebooks/outputs/with-tracklets/train/20\"),\n",
    "    # Path(f\"{REPO_PATH}/notebooks/outputs/with-tracklets/train/75\"),\n",
    "    Path(f\"{REPO_PATH}/notebooks/outputs/with-tracklets/train/88\"),\n",
    "    # Path(f\"{REPO_PATH}/notebooks/outputs/ablation/2022-12-16/12-25-41/0\"),\n",
    "    # Path(f\"{REPO_PATH}/notebooks/outputs/ablation/2022-12-16/12-25-41/1\"),\n",
    "    Path(f\"{REPO_PATH}/notebooks/outputs/ablation/2022-12-16/12-25-41/2\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resolve_color_model(k):\n",
    "    name = k.name\n",
    "    if name == \"20\" or name == \"0\":\n",
    "        return \"c\"\n",
    "    if name == \"75\" or name == \"1\":\n",
    "        return \"m\"\n",
    "    if name == \"88\" or name == \"2\":\n",
    "        return \"y\"\n",
    "\n",
    "\n",
    "def resolve_color_split(k):\n",
    "    name = k.name\n",
    "    # train\n",
    "    if name == \"20\" or name == \"75\" or name == \"88\":\n",
    "        return \"c\"\n",
    "    # test\n",
    "    if name == \"0\" or name == \"1\" or name == \"2\":\n",
    "        return \"m\"\n",
    "\n",
    "\n",
    "def resolve_line_style(k):\n",
    "    name = k.name\n",
    "    # train\n",
    "    if name == \"20\" or name == \"75\" or name == \"88\":\n",
    "        return \"solid\"\n",
    "    # test\n",
    "    if name == \"0\" or name == \"1\" or name == \"2\":\n",
    "        return \"dashed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "percentile_values = []\n",
    "for base_path in base_paths:\n",
    "    args_json = Path(base_path / \"args.json\")\n",
    "    if args_json.exists():\n",
    "        with open(str(args_json), \"r\") as f:\n",
    "            log.info(json.load(f))\n",
    "\n",
    "    # log.info(\"Per frame:\")\n",
    "    # log.info(\"id:, FPR, FNR, Target Detection Rate, % Frames Removed, % Neg Frames Removed\")\n",
    "    pos_frames, neg_frames = [], []\n",
    "    pos_preds, neg_preds = [], []\n",
    "\n",
    "    # accumulate run directories\n",
    "    subdirs = next(os.walk(str(base_path)))[1]\n",
    "    param_set_path = base_path\n",
    "    param_set_results = []\n",
    "    param_set = param_set_path.name\n",
    "    # load every json for that run and append to param_set_results\n",
    "    for f_name in param_set_path.glob(\"**/*.json\"):\n",
    "        with open(f_name, \"r\") as f:\n",
    "            params = json.load(f)\n",
    "            param_set_results.append((params, param_set))\n",
    "\n",
    "    # for each video\n",
    "    for result, param_set_id in param_set_results[2:]:\n",
    "        # per frame binary label and pred\n",
    "        binary_label, binary_pred, _ = calc_tfpnr(\n",
    "            result[\"label\"], result[\"prediction\"], show=False, save=False\n",
    "        )\n",
    "\n",
    "        # per frame list of avg box area\n",
    "        avg_box_area_per_frame = [\n",
    "            avg_box_area(box) for box in label_to_per_frame_list(result[\"label\"])\n",
    "        ]\n",
    "\n",
    "        # create list of all binary labels and preds for positive and negative frames combined with bounding boxe areas\n",
    "        y = zip(binary_label, binary_pred, avg_box_area_per_frame)\n",
    "        for x in y:\n",
    "            if x[0] == 1:\n",
    "                pos_frames.append(x)\n",
    "                pos_preds.append((int(x[0] == x[1]), x[2]))\n",
    "            else:\n",
    "                neg_frames.append(x)\n",
    "                neg_preds.append(int(x[0] == x[1]))\n",
    "\n",
    "    # calc erroneous detection CDF\n",
    "    sorted_pos_frames = sorted(pos_frames, key=lambda y: y[2])\n",
    "    ecdfx = np.array([x[2] for x in sorted_pos_frames])\n",
    "    pos_frames_arr = np.array([x[1] for x in sorted_pos_frames])\n",
    "    fn_idxs = np.where(pos_frames_arr == 0)[0]\n",
    "    raw_ecdfy = np.zeros(len(sorted_pos_frames))\n",
    "    count = 0\n",
    "    for idx in fn_idxs:\n",
    "        raw_ecdfy[idx] = count\n",
    "        count += 1\n",
    "    ecdfy = raw_ecdfy / float(len(raw_ecdfy))\n",
    "\n",
    "    # create detection data bins\n",
    "    bin_size = 500\n",
    "    binned_list = [[] for x in range(ceil(max([y[1] for y in pos_preds]) / bin_size))]\n",
    "    for x in pos_preds:\n",
    "        bin = floor(x[1] / bin_size)\n",
    "        binned_list[bin].append(x)\n",
    "\n",
    "    # calc stats on binned data\n",
    "    bin_stats = []\n",
    "    for idx, bin in enumerate(binned_list):\n",
    "        bin_preds = [x[0] for x in bin]\n",
    "        bin_sizes = [x[1] for x in bin]\n",
    "        bin_mean = np.mean(bin_preds)\n",
    "        bin_std = np.std(bin_preds)\n",
    "        bin_stats.append((bin_mean, bin_std, (idx * bin_size, (idx + 1) * bin_size)))\n",
    "\n",
    "    # calc data distribution CDF\n",
    "    sorted_pos_frames = sorted(pos_frames, key=lambda y: y[2])\n",
    "    ecdfx = np.array([x[2] for x in sorted_pos_frames])\n",
    "    ecdfy_data = np.arange(len(ecdfx)) / float(len(ecdfx))\n",
    "\n",
    "    # calc erroneous detection CDF\n",
    "    # sorted_pos_frames = sorted(pos_frames, key=lambda y: y[2])\n",
    "    # ecdfx = np.array([x[2] for x in sorted_pos_frames])\n",
    "    pos_frames_arr = np.array([x[1] for x in sorted_pos_frames])\n",
    "    fn_idxs = np.where(pos_frames_arr == 0)[0]\n",
    "\n",
    "    if len(fn_idxs) == 0:\n",
    "        ecdfy = np.ones(len(sorted_pos_frames))\n",
    "        perc = 0\n",
    "        ymax_val = 1\n",
    "    else:\n",
    "        raw_ecdfy = np.ones(len(sorted_pos_frames)) * len(fn_idxs)\n",
    "        count = 0\n",
    "        cidx = 0\n",
    "        for idx, _ in enumerate(raw_ecdfy):\n",
    "            if (len(fn_idxs) != cidx) and (idx == fn_idxs[cidx]):\n",
    "                count += 1\n",
    "                raw_ecdfy[fn_idxs[cidx]] = count\n",
    "                cidx += 1\n",
    "            else:\n",
    "                raw_ecdfy[idx] = count\n",
    "        ecdfy = raw_ecdfy / float(len(fn_idxs))\n",
    "        perc_idx = np.where(ecdfy > 0.9)[0][0]\n",
    "        perc = ecdfx[perc_idx]\n",
    "        ymax_val = 0.9\n",
    "        percentile_values.append(perc)\n",
    "\n",
    "    # plt.plot(ecdfx, ecdfy, linestyle=resolve_line_style(base_path), color=resolve_color_model(base_path))\n",
    "    # plt.vlines([perc], ymin=0, ymax=ymax_val, linestyles='dotted', colors=resolve_color_model(base_path))\n",
    "    # plt.xscale('log')\n",
    "    plt.plot(\n",
    "        ecdfx, ecdfy_data, linestyle=\"dashed\", color=resolve_color_split(base_path)\n",
    "    )\n",
    "    plt.plot(ecdfx, ecdfy, linestyle=\"solid\", color=resolve_color_split(base_path))\n",
    "    plt.vlines(\n",
    "        [perc],\n",
    "        ymin=0,\n",
    "        ymax=ymax_val,\n",
    "        linestyles=\"dotted\",\n",
    "        colors=resolve_color_split(base_path),\n",
    "    )\n",
    "    plt.xscale(\"log\")\n",
    "\n",
    "    results[base_path] = bin_stats\n",
    "log.info(percentile_values)\n",
    "log.info(np.mean(percentile_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_start, height, width (list of 100s)\n",
    "fig, axl = plt.subplots(nrows=3, ncols=1, figsize=(10, 20))\n",
    "# plt.title(f\"{base_path}\")\n",
    "idx = {\"c\": 0, \"m\": 1, \"y\": 2}\n",
    "for k, v in results.items():\n",
    "    axi = axl[idx[resolve_color_model(k)]]\n",
    "    if \"train\" in str(k):\n",
    "        axi.bar(\n",
    "            [x[2][0] for x in v],\n",
    "            height=[x[0] for x in v],\n",
    "            color=\"c\",\n",
    "            alpha=0.25,\n",
    "            hatch=\"/\",\n",
    "            width=[bin_size for _ in v],\n",
    "        )\n",
    "    else:\n",
    "        axi.bar(\n",
    "            [x[2][0] for x in v],\n",
    "            height=[x[0] for x in v],\n",
    "            color=\"m\",\n",
    "            alpha=0.25,\n",
    "            width=[bin_size for _ in v],\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot TP/FN vs. Target Size\n",
    "\n",
    "Guiding question:\n",
    "\n",
    "-   Does our TP rate decrease with size?\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot TN/FP for Train and Test\n",
    "\n",
    "Guiding question:\n",
    "\n",
    "-   Does our FP rate differ between the two sets? -> one contains more noise than the other\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tunamelt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "22938593b98fd8161c488a385cf196a491c9023a64785ecad3e6f9b50f83a8c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
